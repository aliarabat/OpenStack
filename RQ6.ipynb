{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import utils.helpers as hpr\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import ast\n",
    "from efficient_apriori import apriori\n",
    "import numpy as np\n",
    "import utils.helpers as hpr\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_openstack_data():\n",
    "    '''Combine generated csv files into a single DataFrame object\n",
    "    '''\n",
    "    df = pd.DataFrame([])\n",
    "    data_path = \"%sChanges/\" % hpr.DIR\n",
    "    changes_file_names = hpr.list_file(data_path)\n",
    "    for f in changes_file_names:\n",
    "        df_per_file = pd.read_csv(\"%s%s\" % (data_path, f))\n",
    "        df = pd.concat((df, df_per_file))\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"number\"])\n",
    "\n",
    "    df = df.sort_values(by=\"updated\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_openstack_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_dependencies = pd.read_csv(\"./Files/all_dependencies.csv\")\n",
    "df_all_dependencies = df_all_dependencies[(df_all_dependencies.is_cross==True)&(df_all_dependencies.status_source==\"MERGED\")&(df_all_dependencies.status_target==\"MERGED\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sample = df_all_dependencies[[\"Source\", \"Target\", \"Source_repo\", \"Target_repo\", \"same_dev\"]].sample(n=381)\n",
    "study_sample.reset_index(drop=True, inplace=True)\n",
    "study_sample[\"Source_repo\"] = study_sample[\"Source_repo\"].map(lambda repo: repo.replace(\"openstack/\", \"\"))\n",
    "study_sample[\"Target_repo\"] = study_sample[\"Target_repo\"].map(lambda repo: repo.replace(\"openstack/\", \"\"))\n",
    "study_sample[\"description\"] = None\n",
    "study_sample[\"relation_type\"] = None\n",
    "study_sample.to_csv(\"./RQs/RQ6/study_sample.csv\", index_label=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association rules mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = pd.read_csv(\"./Files/Repo/extended_paths.csv\")\n",
    "chains = chains[\"Path\"].apply(ast.literal_eval).values.tolist()\n",
    "chains = [list(set(chain)) for chain in chains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing the Apriori algorithm and save itemsets and association rules\n",
    "itemsets, rules = apriori(chains, min_support=0.00005, min_confidence=0.00008, verbosity=0)\n",
    "items = sorted(rules, key=lambda item: (item.lift, item.confidence), reverse=True)\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out every rule with 2 items on the left hand side,\n",
    "# 1 item on the right hand side, sorted by lift\n",
    "rules_rhs = filter(lambda rule: len(rule.lhs) == 1 and len(rule.rhs) == 1, rules)\n",
    "\n",
    "rules = []\n",
    "for rule in sorted(rules_rhs, key=lambda rule: rule.lift):\n",
    "    rule_item = {\"antecedent\": rule.lhs[0], \"consequent\": rule.rhs[0], \"supp\": rule.support, \"conf\": rule.confidence}\n",
    "    rules.append(rule_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = pd.DataFrame(rules).sort_values(by=\"conf\", ascending=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_rules[df_rules.conf<.10])#/len(df_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules.to_csv(\"./RQs/RQ6/Files/association_rules.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_dependencies = pd.read_csv(\"./Files/all_dependencies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cross_project(p):\n",
    "    nbr_cross_project = len(set(hpr.flatten_list(df_all_dependencies.loc[\n",
    "        (df_all_dependencies[\"Source_repo\"]==p) &\n",
    "        (df_all_dependencies[\"is_cross\"]==\"Cross\") &\n",
    "        (df_all_dependencies[\"Source_status\"]==\"MERGED\") & \n",
    "        (df_all_dependencies[\"Target_status\"]==\"MERGED\") &\n",
    "        (df_all_dependencies[\"is_source_bot\"]==False) &\n",
    "        (df_all_dependencies[\"is_target_bot\"]==False), [\"Source\"]].values)))\n",
    "    return nbr_cross_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_projects = pd.DataFrame({\"Project\": df_all_dependencies[\"Source_repo\"].unique().tolist()})\n",
    "df_source_projects[\"Total_changes\"] = df_source_projects[\"Project\"].map(lambda p: len(set(df_all_dependencies.loc[\n",
    "    (df_all_dependencies[\"Source_repo\"]==p) &\n",
    "    (df_all_dependencies[\"Source_status\"]==\"MERGED\") & \n",
    "    (df_all_dependencies[\"Target_status\"]==\"MERGED\") &\n",
    "    (df_all_dependencies[\"is_source_bot\"]==False) &\n",
    "    (df_all_dependencies[\"is_target_bot\"]==False), \"Source\"].values)))\n",
    "df_source_projects[\"Total_cross_project_changes\"] = df_source_projects[\"Project\"].map(count_cross_project)\n",
    "# df_source_projects = df_source_projects[df_source_projects[\"Total_cross_project_changes\"]!=0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_projects.loc[(df_source_projects[\"Total_changes\"]!=0)&(df_source_projects[\"Total_cross_project_changes\"]!=0), [\"Total_changes\", \"Total_cross_project_changes\"]].to_csv(\"./RQs/RQ5_MA/k_means_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X = df_source_projects.loc[(df_source_projects[\"Total_changes\"]!=0)&(df_source_projects[\"Total_cross_project_changes\"]!=0), [\"Total_changes\", \"Total_cross_project_changes\"]].values\n",
    "\n",
    "log_X = np.log(X)\n",
    "\n",
    "# Create a KMeans instance with 2 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit the data to the KMeans model\n",
    "kmeans.fit(log_X)\n",
    "\n",
    "# Get the cluster labels assigned to each data point\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Get the coordinates of the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Visualize the data points and cluster centers\n",
    "plt.scatter(log_X[:, 0], log_X[:, 1], c=labels,)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], marker='x', color='red')\n",
    "plt.xlabel('# of all changes')\n",
    "plt.ylabel('# of cross-project changes')\n",
    "plt.title('K-means Clustering')\n",
    "# plt.xticks(ticks=plt.xticks()[0], labels=np.round(np.exp(plt.xticks()[0]), 2))\n",
    "# plt.yticks(ticks=plt.yticks()[0], labels=np.round(np.exp(plt.yticks()[0]), 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(log_X[:, 0], log_X[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c3f98dc7a618963d8c453529bd2f978a19750ea04392a0abd6ac6b1e473063f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
